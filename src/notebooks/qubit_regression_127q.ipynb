{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# clean data\n",
    "save_path = 'data'\n",
    "\n",
    "input_df = pd.DataFrame()\n",
    "output_df = pd.DataFrame()\n",
    "gtime_df = pd.DataFrame()\n",
    "heatmap_df = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(save_path):\n",
    "    tmp_input_df = pd.read_csv(os.path.join(save_path, file))\n",
    "    tmp_output_df = pd.DataFrame()\n",
    "    tmp_gtime_df = pd.DataFrame()\n",
    "\n",
    "    # output dataframe: ECR error\n",
    "    tmp_output_df['ECR error'] = tmp_input_df['ECR error ']\n",
    "    tmp_output_df['ECR error'] = tmp_output_df['ECR error'].replace('undefined', np.nan)\n",
    "    tmp_output_df['ECR error'] = tmp_output_df['ECR error'].str.split(';')\n",
    "    tmp_output_df = tmp_output_df.explode('ECR error')\n",
    "    tmp_output_df = tmp_output_df.dropna(subset=['ECR error'])\n",
    "    tmp_output_df = tmp_output_df.reset_index(drop=True)\n",
    "    tmp_flattened_output_data = tmp_output_df['ECR error'].values\n",
    "    \n",
    "    # need to create separate dataframe for gate time; no need to flatten yet\n",
    "    tmp_gtime_df['gtime (ns)'] = tmp_input_df['Gate time (ns)']\n",
    "    tmp_gtime_df['gtime (ns)'] = tmp_gtime_df['gtime (ns)'].replace('undefined', np.nan)\n",
    "    tmp_gtime_df['gtime (ns)'] = tmp_gtime_df['gtime (ns)'].str.split(';')\n",
    "    tmp_gtime_df = tmp_gtime_df.explode('gtime (ns)')\n",
    "    tmp_gtime_df = tmp_gtime_df.dropna(subset=['gtime (ns)'])\n",
    "    tmp_gtime_df = tmp_gtime_df.reset_index(drop=True)\n",
    "    \n",
    "    array = tmp_output_df['ECR error'].str.split('_', expand=True)\n",
    "    array[1] = array[1].str.split(':').str[0]\n",
    "    \n",
    "    tmp_input_df = tmp_input_df.drop('ECR error ', axis=1)\n",
    "    tmp_input_df = tmp_input_df.drop('Gate time (ns)', axis=1)\n",
    "    \n",
    "    tmp_heatmap_df = tmp_output_df\n",
    "    # check if the ECR error column has a 1 after the colon; if it does, drop the row\n",
    "    for index, row in tmp_heatmap_df.iterrows():\n",
    "        if ':1' in row['ECR error']:\n",
    "            tmp_heatmap_df = tmp_heatmap_df.drop(index)\n",
    "    tmp_heatmap_df = tmp_heatmap_df.reset_index(drop=True)\n",
    "    avg_ecr_error = dict()\n",
    "    # if found, add the value after the colon in the string into a dictionary\n",
    "    for i in range(127):\n",
    "        for j in range(len(tmp_heatmap_df['ECR error'])):\n",
    "            if tmp_heatmap_df['ECR error'].iloc[j].split(':')[0].split('_')[0] == str(i):\n",
    "                if i not in avg_ecr_error:\n",
    "                    avg_ecr_error[i] = []\n",
    "                avg_ecr_error[i].append(float(tmp_heatmap_df['ECR error'].iloc[j].split(':')[1]))\n",
    "            elif tmp_heatmap_df['ECR error'].iloc[j].split(':')[0].split('_')[1] == str(i):\n",
    "                if i not in avg_ecr_error:\n",
    "                    avg_ecr_error[i] = []\n",
    "                avg_ecr_error[i].append(float(tmp_heatmap_df['ECR error'].iloc[j].split(':')[1]))\n",
    "    \n",
    "    # for every key, average the values and then set that as the value for the key\n",
    "    for key in avg_ecr_error:\n",
    "        avg_ecr_error[key] = sum(avg_ecr_error[key]) / len(avg_ecr_error[key])\n",
    "        tmp_heatmap_df['ECR error'].iat[key] = avg_ecr_error[key]\n",
    "         \n",
    "    # combine tmp_heatmap_df with tmp_input_df; set tmp_heatmap_df as the new dataframe and tmp_heatmap_df at the end\n",
    "    intermediate_df = tmp_input_df\n",
    "    intermediate_df.insert(12, 'ECR error', tmp_heatmap_df['ECR error'])\n",
    "    tmp_heatmap_df = intermediate_df\n",
    "    \n",
    "    # drop all rows that have a invalid ECR error value\n",
    "    for index, row in tmp_heatmap_df.iterrows():\n",
    "        if type(row['ECR error']) != float:\n",
    "            tmp_heatmap_df = tmp_heatmap_df.drop(index)\n",
    "    \n",
    "    tmp_heatmap_df = tmp_heatmap_df.reset_index(drop=True)\n",
    "    heatmap_df = pd.concat([heatmap_df, tmp_heatmap_df])\n",
    "    \n",
    "    # drop all error value columns\n",
    "    # filter_columns = tmp_input_df.filter(like='error', axis=1)\n",
    "    # tmp_input_df = tmp_input_df.drop(columns=filter_columns)\n",
    "    \n",
    "    tmp_formatted_ecrgate_df = pd.DataFrame()\n",
    "    \n",
    "    for index, row in array.iterrows():\n",
    "        found_rows = pd.DataFrame()\n",
    "        for value in row:\n",
    "            found_rows = pd.concat([found_rows, tmp_input_df.loc[tmp_input_df['Qubit'] == int(value)]])\n",
    "        found_rows = pd.concat([found_rows.iloc[0], found_rows.iloc[1]], axis=0).to_frame().T\n",
    "        tmp_formatted_ecrgate_df = pd.concat([tmp_formatted_ecrgate_df, found_rows])\n",
    "    \n",
    "    tmp_formatted_ecrgate_df = tmp_formatted_ecrgate_df.drop('Qubit', axis=1)\n",
    "    tmp_formatted_ecrgate_df = tmp_formatted_ecrgate_df.drop('ECR error', axis=1)\n",
    "    tmp_output_df = pd.concat([tmp_output_df.reset_index(drop=True),tmp_formatted_ecrgate_df.reset_index(drop=True)], axis=1)\n",
    "    tmp_output_df = pd.concat([tmp_output_df.reset_index(drop=True), tmp_gtime_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    tmp_output_df['ECR error'] = tmp_output_df['ECR error'].str.split(':').str[1]\n",
    "    tmp_output_df['gtime (ns)'] = tmp_output_df['gtime (ns)'].str.split(':').str[1]\n",
    "    output_df = pd.concat([output_df, tmp_output_df])\n",
    "    \n",
    "heatmap_df = heatmap_df.reset_index(drop=True)\n",
    "heatmap_df = heatmap_df.drop('Qubit', axis=1)\n",
    "heatmap_df = heatmap_df.drop(index=[870])\n",
    "\n",
    "# for a smaller heatmap\n",
    "heatmap_df = heatmap_df.drop(columns=['ID error ', 'âˆšx (sx) error ', 'Readout assignment error '])\n",
    "\n",
    "output_df = output_df.reset_index(drop=True)\n",
    "output_df = output_df.drop(index=[148,168,991,1007]) # manual dropping; didn't get around to automatically doing it\n",
    "output_df = output_df.reset_index(drop=True)\n",
    "output_df = output_df.astype(float)\n",
    "MAX_ERR = 0.1\n",
    "output_df = output_df[output_df['ECR error'] <= MAX_ERR]\n",
    "for i in range(len(output_df.columns)):\n",
    "    output_df.iloc[:,i] = output_df.iloc[:,i].apply(lambda x: x if x > 0.0 else None)\n",
    "output_df = output_df.dropna(axis=1, how='all')\n",
    "input_df = output_df\n",
    "input_df = input_df.drop('ECR error', axis=1)\n",
    "list_names = input_df.columns\n",
    "output_df = output_df['ECR error']\n",
    "\n",
    "feature_names = list(input_df.keys())\n",
    "print(feature_names)\n",
    "\n",
    "# seaborn plot\n",
    "f, ax = plt.subplots()\n",
    "corr = heatmap_df.corr()\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(corr,\n",
    "            cmap=sns.diverging_palette(h_neg=250, h_pos=10, s=50, as_cmap=True),\n",
    "            vmin=-1.0, vmax=1.0,\n",
    "            square=True, ax=ax,\n",
    "            cbar_kws={'label': '(higher = more correlation)'})\n",
    "ax.set_title('Correlation Matrix')\n",
    "\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42c007b05e5188be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set up regression model\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "X = np.array(input_df)\n",
    "y = np.array(output_df)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X = poly.fit_transform(X)\n",
    "X.astype(float)\n",
    "\n",
    "# standardize data\n",
    "print(\"Original features: %s\\n\" % str(list(enumerate(feature_names))))\n",
    "print(X.shape)\n",
    "X -= np.mean(X, axis=0)\n",
    "Xstd = np.std(X, axis=0)\n",
    "print(\"Standard Deviations: %s\\n\" %str(list(zip(feature_names, Xstd))))\n",
    "x_inds_bad = [i for i in range(len(feature_names)) if Xstd[i] <= 0.00000001]\n",
    "print(\"Bad names: %s\\n\" % str([feature_names[i] for i in x_inds_bad]))\n",
    "feature_names = [feature_names[i] for i in range(len(feature_names)) if i not in x_inds_bad]\n",
    "X = np.delete(X, x_inds_bad, axis=1)\n",
    "X /= np.std(X, axis=0)\n",
    "print(X.shape)\n",
    "\n",
    "print(\"New features: %s\\n\" % str(list(zip(feature_names, X[0]))))\n",
    "\n",
    "y -= np.mean(y)\n",
    "y /= np.std(y)\n",
    "\n",
    "y_mean = np.mean(y)\n",
    "baseline_mse = mean_squared_error(np.ones(len(y), dtype=np.double)*y_mean, y)\n",
    "print(\"Average MSE of average: %f\" % baseline_mse)\n",
    "\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0097f26cac14a4b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# begin training model\n",
    "l1_ratio = 0.5\n",
    "results = []\n",
    "coeff = []\n",
    "\n",
    "for i in range(1):\n",
    "    alpha = 0.11\n",
    "    model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "    \n",
    "    mse_scores = []\n",
    "    r2_scores = []\n",
    "    \n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        mse_scores.append(mse)\n",
    "        r2_scores.append(r2)\n",
    "        \n",
    "    \n",
    "    avg_mse = np.mean(mse_scores)\n",
    "    avg_r2 = np.mean(r2_scores)\n",
    "\n",
    "    print(str({'Alpha': alpha, 'Avg_MSE': avg_mse, 'Avg_R2': avg_r2}))\n",
    "    results.append({'Alpha': alpha, 'Avg_MSE': avg_mse, 'Avg_R2': avg_r2})\n",
    "    print(model.coef_)\n",
    "    coeff.append(model.coef_)\n",
    "    print(\"Non-zero coeffs: %s\" % (str([feature_names[i] for i in range(len(feature_names)) if (model.coef_[i] != 0)]),))\n",
    "    print()\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "# results_coeff_df = pd.DataFrame(coeff, columns=list_names)\n",
    "results_coeff_df = pd.DataFrame(coeff)\n",
    "\n",
    "# plot predicted ECR error vs actual ECR error\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.scatter(y_pred, y_test)\n",
    "plt.xlabel('Predicted ECR error')\n",
    "plt.ylabel('Actual ECR error')\n",
    "plt.title('Predicted ECR error vs Actual ECR error')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "results_df.to_csv('qubit_regression3.csv', index=True)\n",
    "results_coeff_df.to_csv('coefficients3.csv', index=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8b4127490f7ba14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d43c4d6cca96c76a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
